import streamlit as st
from pathlib import Path
import time
import os

from audio_processor import extract_audio, validate_audio_file
from realtime_transcriber import RealtimeTranscriber
from srt_generator import SRTGenerator
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from utils.file_handler import save_uploaded_file, cleanup_file, get_file_info
from config.settings import SUPPORTED_FORMATS, STREAMLIT_MAX_UPLOAD_SIZE, WHISPER_MODEL

# Page configuration
st.set_page_config(
    page_title="× ×ª×Ÿ ×ª××œ×•×œ - ×”××¨×ª ××•×“×™×•/×•×™×“××• ×œ-SRT",
    page_icon="ğŸ¬",
    layout="wide"
)

# Initialize session state
if "transcription_result" not in st.session_state:
    st.session_state.transcription_result = None
if "srt_content" not in st.session_state:
    st.session_state.srt_content = None
if "processing" not in st.session_state:
    st.session_state.processing = False
if "transcribed_words" not in st.session_state:
    st.session_state.transcribed_words = []
if "current_segment" not in st.session_state:
    st.session_state.current_segment = ""


def main():
    # Header
    st.title("ğŸ¬ × ×ª×Ÿ ×ª××œ×•×œ")
    st.markdown("### ×”××¨×ª ××•×“×™×•/×•×™×“××• ×œ×›×ª×•×‘×™×•×ª SRT ×‘×××¦×¢×•×ª MLX-Whisper")
    st.markdown("*××•×ª×× ×¢×‘×•×¨ Apple Silicon (M1/M2) â€¢ ×œ×œ× ×”×’×‘×œ×ª ×’×•×“×œ ×§×•×‘×¥*")
    
    # Sidebar for settings
    with st.sidebar:
        st.header("âš™ï¸ ×”×’×“×¨×•×ª")
        
        # Model selection
        model_options = {
            "mlx-community/whisper-large-v3-turbo": "Large-v3-turbo (809M) - ××”×™×¨ ×•××“×•×™×§ (××•××œ×¥)",
            "mlx-community/whisper-tiny": "Tiny (39M) - ×”×›×™ ××”×™×¨",
            "mlx-community/whisper-small": "Small (244M) - ×××•×–×Ÿ",
            "mlx-community/whisper-medium": "Medium (769M) - ×“×™×•×§ ×˜×•×‘ ×™×•×ª×¨",
            "mlx-community/whisper-large-v3": "Large-v3 (1.5B) - ×“×™×•×§ ××§×¡×™××œ×™"
        }
        
        selected_model = st.selectbox(
            "××•×“×œ Whisper",
            options=list(model_options.keys()),
            format_func=lambda x: model_options[x],
            index=0  # Default to turbo
        )
        
        # Timestamp mode
        timestamp_mode = st.radio(
            "××¦×‘ ×—×•×ª××•×ª ×–××Ÿ",
            options=["sentence", "word", "word_precise"],
            format_func=lambda x: {"sentence": "×‘×¨××ª ××©×¤×˜", "word": "×‘×¨××ª ××™×œ×” (×§×‘×•×¦×•×ª)", "word_precise": "×‘×¨××ª ××™×œ×” (××“×•×™×§)"}[x],
            help="×‘×¨××ª ××©×¤×˜: ×›×ª×•×‘×™×•×ª ×§×¨×™××•×ª | ×‘×¨××ª ××™×œ×” (×§×‘×•×¦×•×ª): ××™×œ×™× ×‘×§×‘×•×¦×•×ª ×§×˜× ×•×ª | ×‘×¨××ª ××™×œ×” (××“×•×™×§): ××™×œ×” ××—×ª ×‘×›×œ ×›×ª×•×‘×™×ª"
        )
        
        st.divider()
        st.markdown("### ××•×“×•×ª")
        st.markdown("""
        ××¤×œ×™×§×¦×™×” ×–×• ××©×ª××©×ª ×‘-**mlx-whisper**, ××™××•×© ××•×ª×× 
        ×©×œ Whisper ×©×œ OpenAI ×¢×‘×•×¨ Apple Silicon.
        
        **×¤×•×¨××˜×™× × ×ª××›×™×:**
        - ×•×™×“××•: MP4, AVI, MOV, MKV, WebM
        - ××•×“×™×•: MP3, WAV, M4A, FLAC, AAC, OGG
        """)
    
    # Main content area
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.header("ğŸ“ ×”×¢×œ××ª ×§×•×‘×¥")
        
        uploaded_file = st.file_uploader(
            "×‘×—×¨ ×§×•×‘×¥ ××•×“×™×• ××• ×•×™×“××•",
            type=SUPPORTED_FORMATS,
            help="×ª×•××š ×‘×›×œ ×’×“×œ×™ ×§×‘×¦×™× - ×¢×™×‘×•×“ ××§×•××™ ×œ×œ× ×”×’×‘×œ×•×ª"
        )
        
        if uploaded_file is not None:
            # Display file info
            st.success(f"âœ… ×§×•×‘×¥ ×”×•×¢×œ×”: {uploaded_file.name}")
            file_size_mb = uploaded_file.size / (1024 * 1024)
            st.info(f"×’×•×“×œ ×”×§×•×‘×¥: {file_size_mb:.2f} MB")
            
            # Process button
            if st.button("ğŸš€ ×”×ª×—×œ ×ª××œ×•×œ", type="primary", disabled=st.session_state.processing):
                st.session_state.processing = True
                st.session_state.transcribed_words = []
                st.session_state.current_segment = ""
                
                # Progress container
                progress_container = st.container()
                with progress_container:
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    try:
                        # Step 1: Save uploaded file
                        status_text.text("×©××™×¨×ª ×”×§×•×‘×¥...")
                        progress_bar.progress(10)
                        input_path = save_uploaded_file(uploaded_file)
                        
                        if not input_path:
                            st.error("×©×’×™××” ×‘×©××™×¨×ª ×”×§×•×‘×¥")
                            st.session_state.processing = False
                            return
                        
                        # Step 2: Extract audio
                        status_text.text("×—×™×œ×•×¥ ××•×“×™×•...")
                        progress_bar.progress(20)
                        audio_path = extract_audio(input_path, lambda msg: status_text.text(msg))
                        
                        if not audio_path:
                            st.error("×©×’×™××” ×‘×—×™×œ×•×¥ ×”××•×“×™×•")
                            cleanup_file(input_path)
                            st.session_state.processing = False
                            return
                        
                        # Step 3: Validate audio
                        status_text.text("×‘×“×™×§×ª ×ª×§×™× ×•×ª ×”××•×“×™×•...")
                        progress_bar.progress(30)
                        is_valid, message = validate_audio_file(audio_path)
                        
                        if not is_valid:
                            st.error(f"×‘×“×™×§×ª ×”××•×“×™×• × ×›×©×œ×”: {message}")
                            cleanup_file(input_path)
                            cleanup_file(audio_path)
                            st.session_state.processing = False
                            return
                        
                        st.info(message)
                        
                        # Step 4: Initialize transcriber
                        status_text.text("×˜×¢×™× ×ª ××•×“×œ Whisper...")
                        progress_bar.progress(40)
                        transcriber = RealtimeTranscriber(selected_model)
                        transcriber.load_model(lambda msg: status_text.text(msg))
                        
                        # Step 5: Transcribe with real-time updates
                        status_text.text("××ª×—×™×œ ×ª××œ×•×œ (×–×” ×¢×œ×•×œ ×œ×§×—×ª ×–××Ÿ)...")
                        progress_bar.progress(60)
                        
                        # Create placeholders for real-time updates
                        if col2:
                            with col2:
                                realtime_placeholder = st.empty()
                                with realtime_placeholder.container():
                                    st.subheader("ğŸ¤ ×ª××œ×•×œ ×‘×–××Ÿ ×××ª")
                                    current_segment_placeholder = st.empty()
                                    words_placeholder = st.empty()
                        
                        def realtime_update(word, segment_info):
                            """Update real-time display"""
                            st.session_state.transcribed_words.append(word)
                            st.session_state.current_segment = segment_info
                            
                            # Update display
                            current_segment_placeholder.markdown(f"**××’×× ×˜ × ×•×›×—×™:** *{segment_info}*")
                            words_text = " ".join(st.session_state.transcribed_words[-30:])  # Show last 30 words
                            words_placeholder.text_area("××™×œ×™× ×©×ª×•××œ×œ×•:", words_text, height=150, disabled=True, key=f"words_{len(st.session_state.transcribed_words)}")
                        
                        result = transcriber.transcribe_with_updates(
                            audio_path, 
                            mode=timestamp_mode,
                            progress_callback=lambda msg: status_text.text(msg),
                            realtime_callback=realtime_update
                        )
                        
                        if not result:
                            st.error("×”×ª××œ×•×œ × ×›×©×œ")
                            cleanup_file(input_path)
                            cleanup_file(audio_path)
                            st.session_state.processing = False
                            return
                        
                        # Step 6: Generate SRT
                        status_text.text("×™×•×¦×¨ ×§×•×‘×¥ SRT...")
                        progress_bar.progress(80)
                        
                        segments = transcriber.extract_segments(result, mode=timestamp_mode)
                        srt_gen = SRTGenerator()
                        srt_content = srt_gen.generate_srt(segments, mode=timestamp_mode)
                        
                        # Step 7: Validate SRT
                        if not srt_gen.validate_srt(srt_content):
                            st.error("××™××•×ª ×§×•×‘×¥ ×”-SRT × ×›×©×œ")
                            cleanup_file(input_path)
                            cleanup_file(audio_path)
                            st.session_state.processing = False
                            return
                        
                        # Store results in session state
                        st.session_state.transcription_result = result
                        st.session_state.srt_content = srt_content
                        
                        # Cleanup
                        cleanup_file(input_path)
                        cleanup_file(audio_path)
                        
                        # Complete
                        progress_bar.progress(100)
                        status_text.text("âœ… ×”×ª××œ×•×œ ×”×•×©×œ×!")
                        time.sleep(1)
                        
                        st.success("×”×ª××œ×•×œ ×”×•×©×œ× ×‘×”×¦×œ×—×”!")
                        st.balloons()
                        
                    except Exception as e:
                        st.error(f"××™×¨×¢×” ×©×’×™××”: {str(e)}")
                    finally:
                        st.session_state.processing = False
    
    with col2:
        st.header("ğŸ“ ×ª×•×¦××•×ª")
        
        # Real-time transcription display
        if st.session_state.processing:
            st.subheader("ğŸ¤ ×ª××œ×•×œ ×‘×–××Ÿ ×××ª")
            realtime_container = st.container()
            with realtime_container:
                if st.session_state.current_segment:
                    st.write("**××’×× ×˜ × ×•×›×—×™:**")
                    st.markdown(f"*{st.session_state.current_segment}*")
                
                if st.session_state.transcribed_words:
                    st.write("**××™×œ×™× ×©×ª×•××œ×œ×•:**")
                    words_text = " ".join(st.session_state.transcribed_words[-50:])  # Show last 50 words
                    st.text_area("", words_text, height=200, disabled=True)
        
        if st.session_state.srt_content:
            # Display transcription
            if st.session_state.transcription_result:
                full_text = st.session_state.transcription_result.get("text", "")
                if full_text:
                    with st.expander("×¦×¤×” ×‘×ª××œ×•×œ ×”××œ×"):
                        st.text_area("×˜×§×¡×˜ ××ª×•××œ×œ", full_text, height=200)
            
            # Display SRT preview
            st.subheader("×ª×¦×•×’×” ××§×“×™××” ×©×œ SRT")
            srt_preview = st.text_area(
                "×ª×•×›×Ÿ SRT", 
                st.session_state.srt_content, 
                height=400,
                help="×–×”×• ×ª×•×›×Ÿ ×§×•×‘×¥ ×”-SRT ×©× ×•×¦×¨"
            )
            
            # Download button
            st.download_button(
                label="â¬‡ï¸ ×”×•×¨×“ ×§×•×‘×¥ SRT",
                data=st.session_state.srt_content,
                file_name=f"{uploaded_file.name.rsplit('.', 1)[0]}.srt" if uploaded_file else "subtitles.srt",
                mime="text/plain",
                type="primary"
            )
            
            # Statistics
            if st.session_state.srt_content:
                lines = st.session_state.srt_content.strip().split('\n')
                subtitle_count = len([l for l in lines if l.strip().isdigit()])
                st.metric("×¡×š ×”×›×œ ×›×ª×•×‘×™×•×ª", subtitle_count)
        else:
            st.info("×”×¢×œ×” ×§×•×‘×¥ ×•×œ×—×¥ ×¢×œ '×”×ª×—×œ ×ª××œ×•×œ' ×›×“×™ ×œ×™×¦×•×¨ ×›×ª×•×‘×™×•×ª")


if __name__ == "__main__":
    main()